{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting Start NN\n",
    "\n",
    "goal:\n",
    "\n",
    "- layers, network, object function, optimizer\n",
    "- setup enviroment\n",
    "- Ex:\n",
    "    - movie review into positive,neg (binary classification)\n",
    "    - classify news by topics (multi-class classification)\n",
    "    - estimate house price (regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Realtion between network, Layers, loss function, optimizer\n",
    "![img](pic/3_1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Layers: \n",
    "  -  logo(r) block of DL\n",
    "  - eg:\n",
    "      - vector data (samaples, features) --- `Dense`\n",
    "      - sequence data (samples, timesteps, features) --- `LSTM` (recurrent)\n",
    "      - image data (samples, weight, height, channel) ---`Convolution2D`      \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "## creating an input 2D tensor first dim:784 --> transform to 32\n",
    "layer=layers.Dense(32, input_shape=(784,)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "automated shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32, input_shape=(784,)))\n",
    "model.add(layers.Dense(16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss :\n",
    "\n",
    "1. binary crossentropy\n",
    "2. categorical crossentropy\n",
    "3. CTC --- for sequential problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "\n",
    "overview\n",
    "1. sequential \n",
    "2. functional api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32,activation='relu',input_shape=(784,)))\n",
    "model.add(layers.Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "functional api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_tensor = layers.Input(shape=(784,))\n",
    "x=layers.Dense(32, activation='relu')(input_tensor)\n",
    "output_tensor = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = models.Model(inputs=input_tensor, outputs=output_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define loss, optimizer, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "             loss='mse',\n",
    "             metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# movie review\n",
    "Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "\n",
    "(train_data, train_labels),(test_data, test_labels) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 22,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 4,\n",
       " 173,\n",
       " 36,\n",
       " 256,\n",
       " 5,\n",
       " 25,\n",
       " 100,\n",
       " 43,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 2,\n",
       " 9,\n",
       " 35,\n",
       " 480,\n",
       " 284,\n",
       " 5,\n",
       " 150,\n",
       " 4,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 2,\n",
       " 336,\n",
       " 385,\n",
       " 39,\n",
       " 4,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 17,\n",
       " 546,\n",
       " 38,\n",
       " 13,\n",
       " 447,\n",
       " 4,\n",
       " 192,\n",
       " 50,\n",
       " 16,\n",
       " 6,\n",
       " 147,\n",
       " 2025,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 4,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 4,\n",
       " 22,\n",
       " 71,\n",
       " 87,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 38,\n",
       " 76,\n",
       " 15,\n",
       " 13,\n",
       " 1247,\n",
       " 4,\n",
       " 22,\n",
       " 17,\n",
       " 515,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 626,\n",
       " 18,\n",
       " 2,\n",
       " 5,\n",
       " 62,\n",
       " 386,\n",
       " 12,\n",
       " 8,\n",
       " 316,\n",
       " 8,\n",
       " 106,\n",
       " 5,\n",
       " 4,\n",
       " 2223,\n",
       " 5244,\n",
       " 16,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 33,\n",
       " 4,\n",
       " 130,\n",
       " 12,\n",
       " 16,\n",
       " 38,\n",
       " 619,\n",
       " 5,\n",
       " 25,\n",
       " 124,\n",
       " 51,\n",
       " 36,\n",
       " 135,\n",
       " 48,\n",
       " 25,\n",
       " 1415,\n",
       " 33,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 77,\n",
       " 52,\n",
       " 5,\n",
       " 14,\n",
       " 407,\n",
       " 16,\n",
       " 82,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 107,\n",
       " 117,\n",
       " 5952,\n",
       " 15,\n",
       " 256,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 3766,\n",
       " 5,\n",
       " 723,\n",
       " 36,\n",
       " 71,\n",
       " 43,\n",
       " 530,\n",
       " 476,\n",
       " 26,\n",
       " 400,\n",
       " 317,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 1029,\n",
       " 13,\n",
       " 104,\n",
       " 88,\n",
       " 4,\n",
       " 381,\n",
       " 15,\n",
       " 297,\n",
       " 98,\n",
       " 32,\n",
       " 2071,\n",
       " 56,\n",
       " 26,\n",
       " 141,\n",
       " 6,\n",
       " 194,\n",
       " 7486,\n",
       " 18,\n",
       " 4,\n",
       " 226,\n",
       " 22,\n",
       " 21,\n",
       " 134,\n",
       " 476,\n",
       " 26,\n",
       " 480,\n",
       " 5,\n",
       " 144,\n",
       " 30,\n",
       " 5535,\n",
       " 18,\n",
       " 51,\n",
       " 36,\n",
       " 28,\n",
       " 224,\n",
       " 92,\n",
       " 25,\n",
       " 104,\n",
       " 4,\n",
       " 226,\n",
       " 65,\n",
       " 16,\n",
       " 38,\n",
       " 1334,\n",
       " 88,\n",
       " 12,\n",
       " 16,\n",
       " 283,\n",
       " 5,\n",
       " 16,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 32,\n",
       " 15,\n",
       " 16,\n",
       " 5345,\n",
       " 19,\n",
       " 178,\n",
       " 32]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9999"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([max(sequence) for sequence in train_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_index = imdb.get_word_index()\n",
    "\n",
    "reverse_word_index = dict([(value,key) for (key,value) in word_index.items()])\n",
    "## deocde the review, indices were offset by 3\n",
    "decode_review = ' '.join([reverse_word_index.get(i-3,'?') for i in train_data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepare data \n",
    "\n",
    "We can't feed list of integer into a nn. Have to turn lists into tensors.Two ways to do it.\n",
    "1. pad lists with the same length, turn into an integer tensor of shape`(samples,word_indices)` =>`Embedding layer`\n",
    "2. one hot encode into vecots of 0s, 1s. => `Dense layer`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode the integer list into binary matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7455"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "def vectorize_sequences(seqs, dimension=10000):\n",
    "    results = np.zeros((len(seqs),dimension))\n",
    "    \n",
    "    for i,seq in enumerate(seqs):\n",
    "        results[i,seq] = 1. \n",
    "    return results.astype('float32')\n",
    "## our vectorize training data\n",
    "x_train = vectorize_sequences(train_data)\n",
    "## vectorized test data\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# should vectorize labels as well\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### building nn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16,activation='relu',input_shape=(10000,)))\n",
    "model.add(layers.Dense(16,activation='relu'))\n",
    "model.add(layers.Dense(1,activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## customized optimizer\n",
    "from keras import optimizers\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 10000)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "15000/15000 [==============================] - 3s 205us/step - loss: 0.5084 - acc: 0.7813 - val_loss: 0.3797 - val_acc: 0.8684\n",
      "Epoch 2/20\n",
      "15000/15000 [==============================] - 1s 82us/step - loss: 0.3004 - acc: 0.9047 - val_loss: 0.3004 - val_acc: 0.8897\n",
      "Epoch 3/20\n",
      "15000/15000 [==============================] - 1s 81us/step - loss: 0.2179 - acc: 0.9285 - val_loss: 0.3085 - val_acc: 0.8711\n",
      "Epoch 4/20\n",
      "15000/15000 [==============================] - 1s 85us/step - loss: 0.1750 - acc: 0.9437 - val_loss: 0.2840 - val_acc: 0.8832\n",
      "Epoch 5/20\n",
      "15000/15000 [==============================] - 1s 84us/step - loss: 0.1427 - acc: 0.9543 - val_loss: 0.2841 - val_acc: 0.8872\n",
      "Epoch 6/20\n",
      "15000/15000 [==============================] - 1s 83us/step - loss: 0.1150 - acc: 0.9650 - val_loss: 0.3167 - val_acc: 0.8774\n",
      "Epoch 7/20\n",
      "15000/15000 [==============================] - 1s 85us/step - loss: 0.0980 - acc: 0.9705 - val_loss: 0.3127 - val_acc: 0.8846\n",
      "Epoch 8/20\n",
      "15000/15000 [==============================] - 1s 87us/step - loss: 0.0807 - acc: 0.9763 - val_loss: 0.3859 - val_acc: 0.8649\n",
      "Epoch 9/20\n",
      "15000/15000 [==============================] - 1s 82us/step - loss: 0.0661 - acc: 0.9821 - val_loss: 0.3635 - val_acc: 0.8782\n",
      "Epoch 10/20\n",
      "15000/15000 [==============================] - 1s 81us/step - loss: 0.0562 - acc: 0.9852 - val_loss: 0.3842 - val_acc: 0.8793\n",
      "Epoch 11/20\n",
      "15000/15000 [==============================] - 1s 86us/step - loss: 0.0438 - acc: 0.9895 - val_loss: 0.4151 - val_acc: 0.8779\n",
      "Epoch 12/20\n",
      "15000/15000 [==============================] - 1s 84us/step - loss: 0.0381 - acc: 0.9920 - val_loss: 0.4530 - val_acc: 0.8687\n",
      "Epoch 13/20\n",
      "15000/15000 [==============================] - 1s 83us/step - loss: 0.0300 - acc: 0.9929 - val_loss: 0.4698 - val_acc: 0.8728\n",
      "Epoch 14/20\n",
      "15000/15000 [==============================] - 1s 85us/step - loss: 0.0247 - acc: 0.9945 - val_loss: 0.5024 - val_acc: 0.8725\n",
      "Epoch 15/20\n",
      "15000/15000 [==============================] - 1s 82us/step - loss: 0.0179 - acc: 0.9977 - val_loss: 0.5319 - val_acc: 0.8705\n",
      "Epoch 16/20\n",
      "15000/15000 [==============================] - 1s 83us/step - loss: 0.0182 - acc: 0.9961 - val_loss: 0.5658 - val_acc: 0.8697\n",
      "Epoch 17/20\n",
      "15000/15000 [==============================] - 1s 90us/step - loss: 0.0102 - acc: 0.9993 - val_loss: 0.6179 - val_acc: 0.8642\n",
      "Epoch 18/20\n",
      "15000/15000 [==============================] - 1s 89us/step - loss: 0.0132 - acc: 0.9969 - val_loss: 0.6371 - val_acc: 0.8677\n",
      "Epoch 19/20\n",
      "15000/15000 [==============================] - 1s 94us/step - loss: 0.0060 - acc: 0.9997 - val_loss: 0.7292 - val_acc: 0.8565\n",
      "Epoch 20/20\n",
      "15000/15000 [==============================] - 1s 86us/step - loss: 0.0053 - acc: 0.9999 - val_loss: 0.7324 - val_acc: 0.8601\n"
     ]
    }
   ],
   "source": [
    "x_val = x_train[:10000]\n",
    "partial_x_train=x_train[10000:]\n",
    "\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train=y_train[10000:]\n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                   partial_y_train,\n",
    "                   epochs=20,\n",
    "                   batch_size=512,\n",
    "                   validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iter_epoch</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>train_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.379684</td>\n",
       "      <td>0.508424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.300373</td>\n",
       "      <td>0.300429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.308532</td>\n",
       "      <td>0.217909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.283978</td>\n",
       "      <td>0.175044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.284149</td>\n",
       "      <td>0.142693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iter_epoch  val_loss  train_loss\n",
       "0           0  0.379684    0.508424\n",
       "1           1  0.300373    0.300429\n",
       "2           2  0.308532    0.217909\n",
       "3           3  0.283978    0.175044\n",
       "4           4  0.284149    0.142693"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val_train_history = pd.DataFrame()\n",
    "df_val_train_history['iter_epoch'] = range(20)\n",
    "df_val_train_history['val_loss']=history.history['val_loss']\n",
    "df_val_train_history['train_loss'] = history.history['loss']\n",
    "df_val_train_history.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f8510d38940>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD6CAYAAAC1W2xyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAGb5JREFUeJzt3X+QlNWd7/H3V2AzExMZQsZChgzM\nraSoiK4/0mycQBDmBowVTCErlc0WRowVEiu3vFauYMDae//IirpgRU2srZCbKi1C8kcWY7ns3UAE\nDBcK9A4gaJGiNghXZ1AvPzKgZjREvveP7oGh6Zl+uvt0Pz/4vKqm5umeM09/69B8+8z3Oec85u6I\niEh2XBJ3ACIiEpYSu4hIxiixi4hkjBK7iEjGKLGLiGSMEruISMYosYuIZIwSu4hIxiixi4hkzMg4\nXvSTn/ykT5o0KY6XFhFJrV27dh1z99Zy7WJJ7JMmTaK7uzuOlxYRSS0z+79R2qkUIyKSMUrsIiIZ\no8QuIpIxsdTYSzl9+jQ9PT28//77cYeSGU1NTUyYMIFRo0bFHYqINFBiEntPTw8f//jHmTRpEmYW\ndzip5+4cP36cnp4eOjo64g5HRBooMaWY999/n7FjxyqpB2JmjB07Vn8BiWTAs3t6mfbwZv5q3Kc/\nF6V9YkbsgJJ6YOpPkXg9u6eXlRsOcKSvn/EtzSy5aTLzrmur+BzLnnmF/tMfRv6dRCV2EZGsKE7I\nvX39LHvmFYCKkvvKDQcqSuqQ4sQe4pNQRKReSiXk/tMfsnLDgYpy1ZG+/opfOzE19koMfBL29vXj\nnPskfHZPb8NimDlzZtB2IpItQyXkShP1+Jbmil87lYl9uE9CEZEkGCohV5qol9w0meZRIyr6nVQm\n9lCfhMUeffRR1q5dC8CPfvQjnn76aW6++WY6Ozu58847azo3wIkTJ5g7dy6dnZ3ce++9ABw9epRZ\ns2Zxww03cPfddw/5nIikS6mE3DxqBEtumlzReeZd18ZD86+mrYIPhFQm9lCfhMVuu+02fvOb3wCw\nadMmrr32Wu6++262bNnCa6+9xttvv13T+VesWMHXvvY1duzYwR//+Ec2bNjA1q1bueqqq9i5cyfT\npk3jzJkzJZ8TkXQZnJANaGtp5qH5V1d1LXDedW1s/34Xf37rD7uitE9lYg/1SVhs4sSJHD9+nPfe\ne4+RI0cyZswY1qxZw+23305fXx/9/bX9RbB//346OzsB6OzsZP/+/dx8880AzJ07l4MHD3LJJZeU\nfE5E0mcgIR96+Cts/35XwyZ4DJsxzKzJzNab2V4zW2MlJkab2Uwz21b4esPM7qhfuHkhPwmL3Xjj\njaxcuZKvfOUr/PSnP2XevHn84he/4NJLL6353FOmTGHnzp0A7Ny5kylTprB9+3a+/vWvs379ejZu\n3MjBgwdLPiciElW56Y4LgR53n2tm64HZwMbBDdz9BWA6gJn9G7CnDnFeYN51bXX59FuwYAHXXnst\nhw8f5tVXX+U73/kOP/nJTzAzjhw5Qi03CFm2bBm33347Tz75JJ///OeZM2cOhw8fZuHChXzwwQdM\nmDCBiRMnMmLEiAueExGJytx96B+a/QJY5+7rzOx7QKu7Lxui7UeBPe5eth6Sy+W8+EYbv//97/ns\nZz9bUfBSnvpVJDvMbJe758q1KzdiHwucLByfAoZL2rOBTcMEtBhYDNDe3l4urtR46623uO222857\nbuLEiWdn14iINFq5xH4MGF04Hl14PJRbgGeG+qG7rwZWQ37EXkGMiTZu3Di2bdsWdxgiImeVm26x\nCZhTOO4CtpRqVLioOhPYHCwyERGpSrnEvhZoM7N9wAngoJmtKtFuKrDf3bVHrIhIzIYtxbj7B8Dc\noqfvK9HuJeCrAeMSEZEqpXPly7bH4NDW8587tDX/fA1efvllXn755Yp/76233mLFihVVv642ChOR\nkNKZ2Nuuh18tOpfcD23NP267vqbTVpvYx40bx/Lly2t6bRGRUNKZ2DtmwIKn8sl884P57wueyj9f\npfvvv58VK1awYsWKsyPomTNnsmzZMr785S8D8Oabb/LFL36Rzs5OHnjggbO/e/jwYRYtWnT28aJF\ni/jBD35AZ2cnX/jCFyq6PZ02ChORWqUzsUM+iefugq3/lP9eQ1IHeOSRR1i+fDnLly/nhRdeAODF\nF19k6tSpZzcGe+ONN3jwwQfZuHEjzz333LDn6+vrY8eOHUyePJndu3dHjkMbhYlIrdKb2A9the6f\nwYyl+e/FNfcApkyZwvz5888+/shHPsKjjz7Kt7/9bd59991hf3dgm9+JEyfy5z//OfJraqMwEalV\nOrPBQE19wVPQ9cC5skyNyb25uZn33nsPAHfnYx/72Hk/X7VqFUuXLmX16tVlbxRd/LtRaaMwEalV\nOhN77+7za+oDNffe6CWPUmbPns26devo7OwsuZr0lltu4Vvf+ha33norl156KUeOHKnp9UpZtmwZ\nv/zlL+ns7KSlpYU5c+bwmc98hqVLlzJ16lQuv/xyJk6cWPI5EREoswlYvWgTsMZRv4pkR6hNwCQA\nbRQmIo2kxN4A2ihMJH2e3dPLyg0HONLXz/iWZpbcNLlhd0CqVaISu7uXvSgp0cVRZhPJgmf39LLs\nmVfoP/0hAL19/Sx75hWAVCT3xFw8bWpq4vjx40pGgbg7x48fp6mpKe5QRFJn5YYDZ5P6gP7TH7Jy\nw4GYIqpMYkbsEyZMoKenh6NHj8YdSmY0NTUxYcKEuMMQSZ0jfaVvXD/U80mTmMQ+atQoOjo64g5D\nRITxLc30lkji41uaY4imcokpxYiIhPDsnl6mPbyZju//G9Me3syze3orPseSmybTPGrEec81jxrB\nkpvK3tI5ERIzYhcRqVWoi54DbTUrRkQkZsNd9Kw0Kc+7ri01ibyYSjEikhlpv+gZihK7iGTGUBc3\n03LRM5Syid3MmsxsvZntNbM1NsQKIjNbamY7zezfzeyvwocqIjK8tF/0DCXKiH0h0OPu1wBjgNnF\nDczsPwFT3P0G4N8BTZ4WkYabd10bD82/mraWZgxoa2nmoflXp7ZWXq0oF0+7gHWF483ALGBjUZv/\nDIwxs63A28CPgkUoIlKBNF/0DCXKiH0scLJwfAr4RIk2rcBRd59BfrQ+vbiBmS02s24z69bqUhGR\n+omS2I8BowvHowuPi50CBjZReA244OPS3Ve7e87dc62trdXEKiIiEURJ7JuAOYXjLmBLiTa7gIHN\n3z9NPrmLiEgMoiT2tUCbme0DTgAHzWzV4AbuvgM4bmb/Bzjg7i+FD1VERKIoe/HU3T8A5hY9fV+J\ndneHCkpERKqnBUoiIhmjxC4ikjHaBExEEiPN9xlNEiV2EUmEtN9nNElUihGRREj7fUaTRIldRBJB\nW+6Go8QuIomgLXfDUWIXkUTQlrvh6OKpiCRC2u8zmiRK7CKSGNpyNwyVYkREMkYjdhGpmRYWJYsS\nu4jURAuLkkelGBGpiRYWJY8Su4jURAuLkkeJXURqooVFyaPELiI10cKi5Ik3sR/aCtseizUEEanN\nvOvaeGj+1bS1NGNAW0szD82/WhdOYxTfrJhDW+FXi2DBU7GFICJhaGFRsgyb2M2sCfgX4FPAPuAb\n7u5FbaYCvwYOF566y92Hvxz+zpvnknrHjKoCF5Haaf55NpUrxSwEetz9GmAMMLtEmzHAP7v79MJX\n+TlO77wFubuU1EViNDD/vLevH+fc/PNn9/TGHZrUqFxi7wJ+WzjeDMwq0WYM8Ldm9pKZrTMzK/uq\nHx8H3T/Ll2NEJBaaf55d5RL7WOBk4fgU8IkSbf4A/IO7/w1wBXBjqROZ2WIz6zaz7qPvj8yXYX61\nSMldJCaaf55d5RL7MWB04Xh04XGxw8Dzg44vL3Uid1/t7jl3z7W2tubLMAuegt7dFQctIrXT/PPs\nKpfYNwFzCsddwJYSbb4H/J2ZXQJcBbwa+dU7ZsD0eyM3F5FwNP88u8ol9rVAm5ntA04AB81sVVGb\nHwN3Ai8Cv3b3/eHDFJHQNP88u6xo9mJD5HI57+7ubvjrioikmZntcvdcuXbaUkBEJGO0H7tISmlx\nkQxFiV0khXRzCxmOSjEiKaTFRTIcJXaRFNLiIhmOSjEiDRaiNj6+pZneEklci4sENGIXaahQG29p\ncZEMR4ldpIFC1ca1uEiGo1KMSAOFrI3r5hYyFI3YRRpIG29JIyixizSQauPSCCrFiDTQQOlEK0al\nnpTYRRpMtXGpN5ViREQyRoldRCRjVIoRiUi7KUpaKLGLRKDdFCVNVIoRiUC7KUqaKLGLRKDdFCVN\nyiZ2M2sys/VmttfM1piZDdP2e2b2fNgQReKnFaOSJlFG7AuBHne/BhgDzC7VyMwmAncEjE0kMbRi\nVNIkSmLvAn5bON4MzBqi3ePAshBBiSSNdlOUNIkyK2YscLJwfAq4YIhiZn8P7AX2hwtNJFm0YlTS\nIkpiPwaMLhyPLjwuNhdoB24CJpvZf3H3Hw9uYGaLgcUA7e3tVQcs6aF53yLxiJLYNwFzgHXkyzI/\nLG7g7n8PYGaTgP9ZnNQLbVYDqwFyuZxXHbGkQtLmfetDRi4mUWrsa4E2M9sHnAAOmtmqWl70ld6T\nTHt4c8W3A5P0SNK871C3oxNJi7Ijdnf/gHypZbD7hmh7GPhSlBeOewQn9ZWked/DfcjovSdZFOsC\nJa3cy64kzftO0oeMSCPEvvJU/7myKUnzvpP0ISPSCLEndv3nyqYkzftO0oeMSCPEuruj/nNlW4h5\n3yFms+h2dHKxiS2xt+k/l5QRcsqkFhfJxSSWUszVbaPZ/v0u/UeTYSVpyqRImsReYxcZimaziFRH\niV0SS7NZRKqjxC6JpdksItXRPU8lsTSbRaQ6SuySaJrNIlI5lWJERDJGiV1EJGOU2EVEMkaJXUQk\nY3TxNEN0lyARASX2zAi5r4o+IETS7aJN7FlLXqHuEpS0e5WKSOUuyhp7Fu+BGWpfFW28JZJ+F2Vi\nz2LyCrWvijbeEkm/YUsxZtYE/AvwKWAf8A1396I2I4FfAuOBA+7+zTrFmrftMbb9qZ37d7ecLaM8\ncn0f0z/6Oky/N9Ipspi8ltw0+bwSClS3r8r4lmZ6S/SDNt4SSY9yI/aFQI+7XwOMAWaXaDMP2Ovu\n04ArzOzawDGeZ9uf2rly+z20n+rGgfZT3Vy5/R62/ak98jmyuGtgqFvRaeMtkfQrd/G0C1hXON4M\nzAI2FrX5DfC/CiP3FuBU0AiL3L+7hfbT9/DjUU/w8w+/xMIRz/Pd0/fw+u4Wts+Jdo5Qo9ukCbGv\nijbeEkm/col9LHCycHwKuCDzufu7AGb2IvCmu79W6kRmthhYDNDeHn10XexIXz+9TOHnH36J/zry\n1zz+l1vZcWYKVkEZRclreNp4SyTdyiX2Y8DowvHowuPzmNlY4F3gC8BmM5vl7luK27n7amA1QC6X\n8+KfRzW+pZn2U90sHPE8j//lVhaOeJ6dZ67k9ctyFZ0nVPIKNW0ya9MvRSQ+5RL7JmAO+XJMF/DD\nEm3+G7Df3X9uZn8C6lqofuT6Pq7c/gTfPX0PO85MYeeZK3ly1BPsv/6Jer5sSaHmfGvuuIiEVO7i\n6Vqgzcz2ASeAg2a2qqjNk8A3zWwHcBzYED7Mc6Z/9HX2T3uC1y/LYcDrl+XYP+2J/KyYBgs1bTKL\n0y9FJD7Djtjd/QNgbtHT9xW16SU/mm+M6fcyHSJfKK2nUNMmszj9UkTic1EuUAol1LTJLE6/FJH4\nKLHXINScb80dF5GQLtpNwEIINW1S0y9FJCQr2iGgIXK5nHd3dzf8dUVE0szMdrl72bndKsWIiGSM\nEruISMYosYuIZIwSu4hIxiixi4hkjBK7iEjGKLGLiGSMEruISMYosYuIZIwSu4hIxlyciX3bY3Bo\n6/nPHdqaf15EJOUuzsTedj38atG55H5oa/5x2/VxRiUiEsTFubtjxwxY8FQ+mefugu6f5R93zIg5\nMBGR2l2cI3bIJ/HcXbD1n/LfldRFJCMu3sR+aGt+pD5jaf57cc1dRCSlhk3sZtZkZuvNbK+ZrTEz\nG6Ld02a208yeM7Pkl3cGauoLnoKuB86VZZTcRSQDyo3YFwI97n4NMAaYXdzAzKYDI939BuAyIAG3\nmS6jd/f5NfWBmnvv7jijEhEJotzougtYVzjeDMwCNha1eRt4vHCcjtLO9HsvfK5jhursIpIJ5RL7\nWOBk4fgUcMHdld39PwDM7FbgDBcmfgo/XwwsBmhvb68yXBERKafcCPsYMLpwPLrw+AJm9lXgHuAW\nd/9LqTbuvtrdc+6ea21trTZeEREpo1xi38S5mnkXsKW4gZmNA5YAc939nbDhiYhIpcol9rVAm5nt\nA04AB81sVVGbO4ArgA1mts3MvlmHOEVEJCJz94a/aC6X8+7u7oa/bnDbHstvQzD4ouuhrfnZNaUu\n0IqI1MDMdrl7rly7dMxiSSrtOSMiCZT8xURJpj1nRCSBNGKvlfacEZGEUWKvlfacEZGEUWKvhfac\nEZEEUmKvhfacEZEE0sXTWmjPGRFJII3YRUQyRok9CXRzbREJSIk9CbTQSUQCUo09CbTQSUQC0og9\nKbTQSUQCUWJPCi10EpFAlNiTQAudRCQgJfYk0EInEQlIF0+TIMRCJ+0NLyIFGrFnhaZMikiBRuxZ\noSmTIlKgEXuWaMqkiFAmsZtZk5mtN7O9ZrbGzGyIdqPM7F/rE6JEpimTIkL5EftCoMfdrwHGALOL\nG5hZM7Cr1M+kgUJNmdS+NSKpVy6xdwG/LRxvBmYVN3D3fnf/a6AncGxSiVBTJnURViT1yl08HQuc\nLByfAiZX+0JmthhYDNDe3l7taWQoofaG10VYkdQrN2I/BowuHI8uPK6Ku69295y751pbW6s9jTSC\nLsKKpFq5xL4JmFM47gK21DccSYQQF2FVqxeJTbnEvhZoM7N9wAngoJmtqn9YEptQF2FVqxeJjbl7\nw180l8t5d3d3w19XIgi5NcFAMletXiQIM9vl7rly7bTyVM4X8gbdg2v1M5YqqYs0iFaeSv3UWqtX\nnV6kKkrsUh8havWq04tURYld6iPEgqnBc+o3P3jug0IlHZFhKbFLfUy/98IE3DGj8guwIebUq6Qj\nFxkldkm2EHPqVdKRi4xmxUhyDa7Td8yAji9WV47RNglykdGIXZIr5L1gay3pqJwjKaLELskVqk4P\ntZd0VM6RFFFil+wLMfUy1AwdjfylAZTYJftClXRCzNDRyF8aQHvFiEQVau+bEOcJuaePpEbUvWI0\nYheJItSul6CRv9SdErtIFCFn6ISYmx+i5q96f2YpsYtEEWqGTpJG/qFG/aE+IPRBE4wSu0gjJWnk\nH2qmT6gPCJWXgtHFU5E0Kl6VW/y4EpsfPLdnftcDtcWThAvLIST04rQunopkWaiRf4h6/8Drh7gB\nelJWCKf8rwcldpE0ClHzD1nvD/UBkZQVwkm6OF3qPOW4+5BfQBOwHtgLrKFQuqm0TfHX5z73OReR\nmP3vH7q/9rvzn3vtd/nnK/Ha79wf6Th3ruLHcZ1n0z9W9/uDbfpH9/9xWf57perQL0C3l8mv7l52\nxL4Q6HH3a4AxwOwq24hI0oSa6ROqLJSkFcKQnIvTg87zqctsfJRfKZfYu4DfFo43A7OqbCMiWRXq\nAyLklNJay0KhylSBrz1cfqldEaV5ucQ+FjhZOD4FfKLKNpjZYjPrNrPuo0ePRolNRKQyoRJy0i5O\nF87z/97zN6M0L5fYjwGjC8ejC4+raYO7r3b3nLvnWltbo8QmIlKZUAk5SRenB53njVN+JMqvlEvs\nm4A5heMuYEuVbURE6i/kHv61qte1hwiGXaBkZh8B1gHt5Ge9/Hfgu+5+3zBtvuHDnRQtUBIRqUbU\nBUrD3vPU3T8A5hY9fV+ENiIiEhMtUBIRyRgldhGRjFFiFxHJGCV2EZGMiWXbXjN7BzjQ8Beu3icZ\nYn5+Qine+lK89Ze2mBsV70R3L7sQaNhZMXV0IMqUnaQws27FWz+Kt77SFi+kL+akxatSjIhIxiix\ni4hkTFyJfXVMr1stxVtfire+0hYvpC/mRMUby8VTERGpH5ViREQypm6J3cyazGy9me01szVmZtW0\naSQze9rMdprZc2Z2wYwhM5tqZj1mtq3wNTmOOKPGksD+nTko3jfM7I4SbWLvYzMbZWb/WjiO1Idx\n9vXgeAuPh30fF9rE1s9F/Rspjrjfy0Uxl30fF9rF1sf1HLGn6rZ6ZjYdGOnuNwCXcW4r4sHGAP/s\n7tMLX3HOxY8SS2L6F8DdXxiIF9gH7CnRLNY+NrNmYBfn+ipqH8bS18XxRnwfQ0z9XKJ/o8YR23u5\nOOaI72OI8b1cz8SettvqvQ08Xjgeql/GAH9rZi+Z2bqYR8BRYklS/55lZh8FPu3u+0r8ONY+dvd+\nd/9roKfwVNQ+jKWvS8Qb5X0MMfVziXijxhHbe7lEzEDZ9zHE+F6uZ2IPdlu9RnD3/3D3l8zsVuAM\nsLFEsz8A/+DufwNcAdzYyBiriCUx/VtkNvkbtJSSpD6G6H2YiL6O+D6G5PRz1DgS0b9FhnsfQ4x9\nXM+Vp8Fuq9coZvZV4B7gFnf/S4kmh4FXBx1f3pjISjpM+VgS1b+D3AI8M8TPDpOcPobofZiYvo7w\nPobk9HPUOBLTv4MM9z6GGPu4niP2VN1Wz8zGAUuAue7+zhDNvgf8nZldAlzFuX+0OESJJTH9O6Dw\n5+hM8n9Ol5KkPobofZiIvo74Pobk9HPUOBLRvwMivI8hxj6uZ2JfC7SZ2T7gBHDQzFaVaTPcnzX1\ndgf5P5c2FK5g31Ui3h8DdwIvAr929/2NDnKoWID+hPfvgKnAfnd/38w6Et7HUKIPh4g7KX1d/D7+\nZsL7+YI4Et6/A86+jwGS1sdaoCQikjFaoCQikjFK7CIiGaPELiKSMUrsIiIZo8QuIpIxSuwiIhmj\nxC4ikjH/H59Dj8g7G+ZIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f850af84080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_val_train_history.iloc[:,1:3].plot(style=['o','x'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we must prevent overfitting: early stop at epoch 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/4\n",
      "15000/15000 [==============================] - 2s 117us/step - loss: 0.4908 - acc: 0.7903 - val_loss: 0.3706 - val_acc: 0.8669\n",
      "Epoch 2/4\n",
      "15000/15000 [==============================] - 1s 83us/step - loss: 0.2880 - acc: 0.9037 - val_loss: 0.3064 - val_acc: 0.8803\n",
      "Epoch 3/4\n",
      "15000/15000 [==============================] - 1s 92us/step - loss: 0.2144 - acc: 0.9298 - val_loss: 0.2764 - val_acc: 0.8924\n",
      "Epoch 4/4\n",
      "15000/15000 [==============================] - 1s 86us/step - loss: 0.1716 - acc: 0.9446 - val_loss: 0.2758 - val_acc: 0.8891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8500a81c88>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16,activation='relu',input_shape=(10000,)))\n",
    "model.add(layers.Dense(16,activation='relu'))\n",
    "model.add(layers.Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(partial_x_train,\n",
    "                   partial_y_train,\n",
    "                   epochs=4,\n",
    "                   batch_size=512,\n",
    "                   validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 2s 87us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2963907635498047, 0.87951999999999997]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.evaluate(x_test,y_test)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pretty naive get 88% accuracy, but for a state-of-art approach one should get close to 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.22995768],\n",
       "       [ 0.99805248],\n",
       "       [ 0.85154974],\n",
       "       ..., \n",
       "       [ 0.09068668],\n",
       "       [ 0.12663822],\n",
       "       [ 0.52619237]], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some are less confident"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Routers datasets \n",
    "multi-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(train_data, train_labels),(test_data, test_labels)=reuters.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8982,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2246"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 245,\n",
       " 273,\n",
       " 207,\n",
       " 156,\n",
       " 53,\n",
       " 74,\n",
       " 160,\n",
       " 26,\n",
       " 14,\n",
       " 46,\n",
       " 296,\n",
       " 26,\n",
       " 39,\n",
       " 74,\n",
       " 2979,\n",
       " 3554,\n",
       " 14,\n",
       " 46,\n",
       " 4689,\n",
       " 4329,\n",
       " 86,\n",
       " 61,\n",
       " 3499,\n",
       " 4795,\n",
       " 14,\n",
       " 61,\n",
       " 451,\n",
       " 4329,\n",
       " 17,\n",
       " 12]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_index = reuters.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_word_index=dict([(value,key) for key,value in word_index.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([reverse_word_index.get(i-3,'?') for i in train_data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "def vectorize_sequence(seqs, dim=10000):\n",
    "    results=np.zeros((len(seqs), dim))\n",
    "    for i, seq in enumerate(seqs):\n",
    "        results[i, seq] = 1\n",
    "    return results\n",
    "\n",
    "x_train = vectorize_sequence(train_data)\n",
    "x_test  = vectorize_sequence(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for multi-class categorical labels ,we could use \n",
    "1. one hot labels(categorical encoding)\n",
    "2. integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_one_hot(labels, dim=46):\n",
    "    results=np.zeros((len(labels),dim))\n",
    "    for i,label in enumerate(labels):\n",
    "        results[i,label]=1        \n",
    "    return results\n",
    "\n",
    "one_hot_train_labels=to_one_hot(train_labels)\n",
    "one_hot_test_labels =to_one_hot(test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "one_hot_train_labels=to_categorical(train_labels)\n",
    "one_hot_test_labels =to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64,activation='relu',input_shape=(10000,)))\n",
    "model.add(layers.Dense(64,activation='relu'))\n",
    "model.add(layers.Dense(46,activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 2s 266us/step - loss: 2.5322 - acc: 0.4955 - val_loss: 1.7208 - val_acc: 0.6120\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 2s 215us/step - loss: 1.4452 - acc: 0.6879 - val_loss: 1.3459 - val_acc: 0.7060\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 2s 217us/step - loss: 1.0953 - acc: 0.7651 - val_loss: 1.1708 - val_acc: 0.7430\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 2s 215us/step - loss: 0.8697 - acc: 0.8165 - val_loss: 1.0793 - val_acc: 0.7590\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 2s 217us/step - loss: 0.7034 - acc: 0.8472 - val_loss: 0.9844 - val_acc: 0.7810\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 2s 223us/step - loss: 0.5667 - acc: 0.8802 - val_loss: 0.9411 - val_acc: 0.8040\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 2s 228us/step - loss: 0.4581 - acc: 0.9048 - val_loss: 0.9083 - val_acc: 0.8020\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 2s 221us/step - loss: 0.3695 - acc: 0.9231 - val_loss: 0.9363 - val_acc: 0.7890\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 2s 218us/step - loss: 0.3032 - acc: 0.9315 - val_loss: 0.8917 - val_acc: 0.8090\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 2s 217us/step - loss: 0.2537 - acc: 0.9414 - val_loss: 0.9071 - val_acc: 0.8110\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 2s 218us/step - loss: 0.2187 - acc: 0.9471 - val_loss: 0.9177 - val_acc: 0.8130\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 2s 226us/step - loss: 0.1873 - acc: 0.9508 - val_loss: 0.9027 - val_acc: 0.8130\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 2s 224us/step - loss: 0.1703 - acc: 0.9521 - val_loss: 0.9323 - val_acc: 0.8110\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 2s 218us/step - loss: 0.1536 - acc: 0.9554 - val_loss: 0.9689 - val_acc: 0.8050\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 2s 219us/step - loss: 0.1389 - acc: 0.9560 - val_loss: 0.9678 - val_acc: 0.8160\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 2s 219us/step - loss: 0.1314 - acc: 0.9562 - val_loss: 1.0211 - val_acc: 0.8060\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 2s 226us/step - loss: 0.1217 - acc: 0.9580 - val_loss: 1.0255 - val_acc: 0.7970\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 2s 219us/step - loss: 0.1198 - acc: 0.9583 - val_loss: 1.0424 - val_acc: 0.8050\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 2s 227us/step - loss: 0.1138 - acc: 0.9593 - val_loss: 1.0963 - val_acc: 0.7970\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 2s 226us/step - loss: 0.1111 - acc: 0.9592 - val_loss: 1.0691 - val_acc: 0.8000\n"
     ]
    }
   ],
   "source": [
    "x_val = x_train[:1000]\n",
    "y_val = one_hot_train_labels[:1000]\n",
    "\n",
    "partial_x_train = x_train[1000:]\n",
    "partial_y_train = one_hot_train_labels[1000:]\n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                   partial_y_train,\n",
    "                   epochs=20,\n",
    "                   batch_size=512,\n",
    "                   validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.5322070564431556,\n",
       " 1.4452011329851124,\n",
       " 1.0952716509939227,\n",
       " 0.869665648996367,\n",
       " 0.70335559949812754,\n",
       " 0.56665067177194006,\n",
       " 0.4581338031209522,\n",
       " 0.36954388210600825,\n",
       " 0.30321335393036558,\n",
       " 0.25373416116021985,\n",
       " 0.2186693005680112,\n",
       " 0.18727144439532267,\n",
       " 0.17026738734718433,\n",
       " 0.15355414264529488,\n",
       " 0.13890272172075022,\n",
       " 0.13136214125771714,\n",
       " 0.121675618101155,\n",
       " 0.11978278411409964,\n",
       " 0.11377048683969994,\n",
       " 0.11111346340827612]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval_loss = pd.DataFrame({\n",
    "    'epoch':range(20),\n",
    "    'train_loss':history.history['loss'],\n",
    "    'val_loss':history.history['val_loss'],\n",
    "    'train_acc':history.history['acc'],\n",
    "    'val_acc':history.history['val_acc']\n",
    "    })\n",
    "df_eval_loss.set_index(df_eval_loss.epoch,drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f1164409438>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAEGCAYAAABxfL6kAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2AEgMgQ7AESGYAeAyPx//wmLTwy0cEgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1163e61400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_eval_loss.loc[:,['train_loss','val_loss']].plot(style=['x','o'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f1163b16320>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAEGCAYAAABxfL6kAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMP8PqRcFEsULLmEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1163cb5320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_eval_loss.loc[:,['train_acc','val_acc']].plot(style=['x','o'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8982 samples, validate on 2246 samples\n",
      "Epoch 1/9\n",
      "8982/8982 [==============================] - 2s 255us/step - loss: 2.4437 - acc: 0.5332 - val_loss: 1.6612 - val_acc: 0.6478\n",
      "Epoch 2/9\n",
      "8982/8982 [==============================] - 2s 228us/step - loss: 1.3241 - acc: 0.7161 - val_loss: 1.3108 - val_acc: 0.7021\n",
      "Epoch 3/9\n",
      "8982/8982 [==============================] - 2s 233us/step - loss: 0.9744 - acc: 0.7869 - val_loss: 1.1418 - val_acc: 0.7489\n",
      "Epoch 4/9\n",
      "8982/8982 [==============================] - 2s 228us/step - loss: 0.7565 - acc: 0.8390 - val_loss: 1.0410 - val_acc: 0.7663\n",
      "Epoch 5/9\n",
      "8982/8982 [==============================] - 2s 227us/step - loss: 0.5963 - acc: 0.8764 - val_loss: 0.9861 - val_acc: 0.7783\n",
      "Epoch 6/9\n",
      "8982/8982 [==============================] - 2s 228us/step - loss: 0.4751 - acc: 0.9009 - val_loss: 0.9737 - val_acc: 0.7890\n",
      "Epoch 7/9\n",
      "8982/8982 [==============================] - 2s 228us/step - loss: 0.3831 - acc: 0.9175 - val_loss: 0.9541 - val_acc: 0.7912\n",
      "Epoch 8/9\n",
      "8982/8982 [==============================] - 2s 229us/step - loss: 0.3076 - acc: 0.9348 - val_loss: 0.9627 - val_acc: 0.7961\n",
      "Epoch 9/9\n",
      "8982/8982 [==============================] - 2s 228us/step - loss: 0.2591 - acc: 0.9414 - val_loss: 0.9800 - val_acc: 0.7903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f10fcba1eb8>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64,activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64,activation='relu'))\n",
    "model.add(layers.Dense(46,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.fit(x_train,\n",
    "          one_hot_train_labels,\n",
    "          epochs=9,\n",
    "          batch_size=512,\n",
    "          validation_data=(x_test,one_hot_test_labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246/2246 [==============================] - 1s 225us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.98003143321586739, 0.79029385579662037]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, one_hot_test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy \n",
    "test_labels_copy= test_labels.copy()\n",
    "np.random.shuffle(test_labels_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19723953695458593"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(test_labels_copy==test_labels)/len(test_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46,)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(pred[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treat another labels \n",
    "integer labels\n",
    "\n",
    "- `sparse_categorical_crossentropy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(train_labels)\n",
    "y_test  = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8982 samples, validate on 2246 samples\n",
      "Epoch 1/20\n",
      "8982/8982 [==============================] - 2s 251us/step - loss: 2.4444 - acc: 0.5283 - val_loss: 1.6989 - val_acc: 0.6594\n",
      "Epoch 2/20\n",
      "8982/8982 [==============================] - 2s 225us/step - loss: 1.3641 - acc: 0.7067 - val_loss: 1.3250 - val_acc: 0.7115\n",
      "Epoch 3/20\n",
      "8982/8982 [==============================] - 2s 224us/step - loss: 1.0183 - acc: 0.7806 - val_loss: 1.1714 - val_acc: 0.7329\n",
      "Epoch 4/20\n",
      "8982/8982 [==============================] - 2s 226us/step - loss: 0.7939 - acc: 0.8297 - val_loss: 1.0548 - val_acc: 0.7720\n",
      "Epoch 5/20\n",
      "8982/8982 [==============================] - 2s 229us/step - loss: 0.6274 - acc: 0.8699 - val_loss: 0.9885 - val_acc: 0.7792\n",
      "Epoch 6/20\n",
      "8982/8982 [==============================] - 2s 226us/step - loss: 0.4990 - acc: 0.8974 - val_loss: 0.9585 - val_acc: 0.7872\n",
      "Epoch 7/20\n",
      "8982/8982 [==============================] - 2s 226us/step - loss: 0.4023 - acc: 0.9134 - val_loss: 0.9389 - val_acc: 0.7898\n",
      "Epoch 8/20\n",
      "8982/8982 [==============================] - 2s 228us/step - loss: 0.3245 - acc: 0.9285 - val_loss: 0.9631 - val_acc: 0.7930\n",
      "Epoch 9/20\n",
      "8982/8982 [==============================] - 2s 233us/step - loss: 0.2737 - acc: 0.9378 - val_loss: 0.9520 - val_acc: 0.7965\n",
      "Epoch 10/20\n",
      "8982/8982 [==============================] - 2s 232us/step - loss: 0.2336 - acc: 0.9446 - val_loss: 0.9500 - val_acc: 0.8037\n",
      "Epoch 11/20\n",
      "8982/8982 [==============================] - 2s 233us/step - loss: 0.2030 - acc: 0.9496 - val_loss: 0.9787 - val_acc: 0.8019\n",
      "Epoch 12/20\n",
      "8982/8982 [==============================] - 2s 227us/step - loss: 0.1776 - acc: 0.9515 - val_loss: 1.0222 - val_acc: 0.7952\n",
      "Epoch 13/20\n",
      "8982/8982 [==============================] - 2s 230us/step - loss: 0.1620 - acc: 0.9515 - val_loss: 1.0209 - val_acc: 0.7996\n",
      "Epoch 14/20\n",
      "8982/8982 [==============================] - 2s 228us/step - loss: 0.1533 - acc: 0.9527 - val_loss: 1.1445 - val_acc: 0.7801\n",
      "Epoch 15/20\n",
      "8982/8982 [==============================] - 2s 236us/step - loss: 0.1373 - acc: 0.9552 - val_loss: 1.0780 - val_acc: 0.7934\n",
      "Epoch 16/20\n",
      "8982/8982 [==============================] - 2s 232us/step - loss: 0.1359 - acc: 0.9560 - val_loss: 1.1070 - val_acc: 0.7921\n",
      "Epoch 17/20\n",
      "8982/8982 [==============================] - 2s 228us/step - loss: 0.1260 - acc: 0.9539 - val_loss: 1.1472 - val_acc: 0.7876\n",
      "Epoch 18/20\n",
      "8982/8982 [==============================] - 2s 234us/step - loss: 0.1249 - acc: 0.9551 - val_loss: 1.1307 - val_acc: 0.7965\n",
      "Epoch 19/20\n",
      "8982/8982 [==============================] - 2s 228us/step - loss: 0.1214 - acc: 0.9537 - val_loss: 1.1857 - val_acc: 0.7894\n",
      "Epoch 20/20\n",
      "8982/8982 [==============================] - 2s 236us/step - loss: 0.1166 - acc: 0.9547 - val_loss: 1.1601 - val_acc: 0.7930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f10fc74c278>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64,activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64,activation='relu'))\n",
    "model.add(layers.Dense(46,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          epochs=20,\n",
    "          batch_size=512,\n",
    "          validation_data=(x_test,y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boston house price prediction \n",
    "regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import boston_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(train_data, train_targets),(test_data, test_targets) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 13)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.23247000e+00,   0.00000000e+00,   8.14000000e+00, ...,\n",
       "          2.10000000e+01,   3.96900000e+02,   1.87200000e+01],\n",
       "       [  2.17700000e-02,   8.25000000e+01,   2.03000000e+00, ...,\n",
       "          1.47000000e+01,   3.95380000e+02,   3.11000000e+00],\n",
       "       [  4.89822000e+00,   0.00000000e+00,   1.81000000e+01, ...,\n",
       "          2.02000000e+01,   3.75520000e+02,   3.26000000e+00],\n",
       "       ..., \n",
       "       [  3.46600000e-02,   3.50000000e+01,   6.06000000e+00, ...,\n",
       "          1.69000000e+01,   3.62250000e+02,   7.83000000e+00],\n",
       "       [  2.14918000e+00,   0.00000000e+00,   1.95800000e+01, ...,\n",
       "          1.47000000e+01,   2.61950000e+02,   1.57900000e+01],\n",
       "       [  1.43900000e-02,   6.00000000e+01,   2.93000000e+00, ...,\n",
       "          1.56000000e+01,   3.76700000e+02,   4.38000000e+00]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler().fit(train_data)\n",
    "train_data_c = sc.fit_transform(train_data)\n",
    "test_data_c = sc.transform(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = train_data.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 13)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = train_data.mean(axis=0)\n",
    "train_data -= mean\n",
    "std = train_data.std(axis=0)\n",
    "train_data /= std\n",
    "\n",
    "test_data -= mean\n",
    "test_data /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "np.sum(~np.isclose(train_data_c,train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "np.sum(~np.isclose(test_data,test_data_c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 13)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102, 13)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(64,activation='relu',input_shape=(train_data.shape[1],)))\n",
    "#     model.add(layers.Dense(64,activation='relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer='rmsprop',loss='mse',metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kfold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "val_mse:8.20,\tval_mae1.81\n",
      "processing fold # 1\n",
      "val_mse:8.86,\tval_mae2.34\n",
      "processing fold # 2\n",
      "val_mse:15.65,\tval_mae2.64\n",
      "processing fold # 3\n",
      "val_mse:13.58,\tval_mae2.30\n",
      "complete\n"
     ]
    }
   ],
   "source": [
    "k = 4 \n",
    "\n",
    "num_val_samples = len(train_data)//k\n",
    "all_scores = []\n",
    "for i in range(k):\n",
    "    print('processing fold #',i)\n",
    "    \n",
    "    # prepare from k partition \n",
    "    val_data = train_data[i*num_val_samples:(i+1)*num_val_samples]\n",
    "    val_targets = train_targets[ i*num_val_samples:(i+1)*num_val_samples]\n",
    "    \n",
    "    #prepare train data\n",
    "    partial_train_data = np.concatenate([\n",
    "        train_data[:i*num_val_samples], train_data[(i+1)*num_val_samples:]        \n",
    "    ],axis=0)\n",
    "    \n",
    "    partial_train_targets = np.concatenate([\n",
    "        train_targets[:i*num_val_samples], train_targets[(i+1)*num_val_samples:]\n",
    "    ],axis=0)\n",
    "    \n",
    "    # build model\n",
    "    model = build_model() #compiled\n",
    "    # train in silent mode verbose=0\n",
    "    model.fit(partial_train_data,partial_train_targets,\n",
    "             epochs=100, batch_size=1, verbose=0)\n",
    "    # evaluate on val sets\n",
    "    val_mse, val_mae = model.evaluate(val_data, val_targets,verbose=0)\n",
    "    print('val_mse:{:.2f},\\tval_mae:{:.2f}'.format(val_mse,val_mae))\n",
    "    all_scores.append(val_mae)\n",
    "print('complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.8074767849232891,\n",
       " 2.3398187113280344,\n",
       " 2.6428324562488217,\n",
       " 2.2966304061436418]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2716895896609466"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "processing fold # 1\n",
      "processing fold # 2\n",
      "processing fold # 3\n",
      "complete\n"
     ]
    }
   ],
   "source": [
    "k = 4 \n",
    "\n",
    "num_val_samples = len(train_data)//k\n",
    "all_mae_histories = []\n",
    "for i in range(k):\n",
    "    print('processing fold #',i)\n",
    "    \n",
    "    # prepare from k partition \n",
    "    val_data = train_data[i*num_val_samples:(i+1)*num_val_samples]\n",
    "    val_targets = train_targets[ i*num_val_samples:(i+1)*num_val_samples]\n",
    "    \n",
    "    #prepare train data\n",
    "    partial_train_data = np.concatenate([\n",
    "        train_data[:i*num_val_samples], train_data[(i+1)*num_val_samples:]        \n",
    "    ],axis=0)\n",
    "    \n",
    "    partial_train_targets = np.concatenate([\n",
    "        train_targets[:i*num_val_samples], train_targets[(i+1)*num_val_samples:]\n",
    "    ],axis=0)\n",
    "    \n",
    "    # build model\n",
    "    model = build_model() #compiled\n",
    "    # train in silent mode verbose=0\n",
    "    \n",
    "    history = model.fit(partial_train_data,partial_train_targets,\n",
    "                        validation_data = (val_data,val_targets),\n",
    "                        epochs=500, batch_size=1, verbose=0)\n",
    "    mae_history=history.history['val_mean_absolute_error']    \n",
    "    all_mae_histories.append(mae_history)\n",
    "print('complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_mae_history=[np.mean([x[i] for x in all_mae_histories]) for i in range(500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f99a4425d68>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAD6CAYAAABXh3cLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f99affded30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(500),avg_mae_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
