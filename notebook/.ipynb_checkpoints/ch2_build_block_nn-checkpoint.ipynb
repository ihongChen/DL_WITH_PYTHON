{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. first example of nn\n",
    "2. what is tensor, data format underlying all DL\n",
    "3. tensor operation building blocks of nn\n",
    "4. how nn learn from data : gradient descnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation='relu',input_shape=(28*28,)))\n",
    "network.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how to compile: optimizaion,loss, eval metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(optimizer='rmsprop',\n",
    "               loss='categorical_crossentropy',\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000,28*28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_images = train_images.astype('float32')/255\n",
    "\n",
    "test_images = test_images.reshape((10000,28*28))\n",
    "test_images = test_images.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ihong/anaconda3/lib/python3.6/site-packages/keras/models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 8s 136us/step - loss: 0.2555 - acc: 0.9271\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 8s 137us/step - loss: 0.1026 - acc: 0.9688\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 8s 134us/step - loss: 0.0676 - acc: 0.9798\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 8s 135us/step - loss: 0.0488 - acc: 0.9853\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 8s 135us/step - loss: 0.0370 - acc: 0.9887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f929a417978>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(train_images, train_labels, nb_epoch=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluation network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 97us/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97950000000000004"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(12)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "x= np.array(12)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.array([1,2,3]) ## 3 dimension\n",
    "print(x)\n",
    "x.ndim ## one axis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 5)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.array([[1,2,3,1,0],[4,3,2,5,6],[1,2,3,4,5]])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=np.array([[[1,2,3,4,5],[1,2,3,4,1],[2,3,1,1,1]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 5)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "back to nn train_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(train_images.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n"
     ]
    }
   ],
   "source": [
    "print(train_images.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9274024da0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAAD6CAYAAACF8ip6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f926ec84748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "digit = train_images[4]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(digit,cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
